# Contribuir a este proyecto

隆Gracias por tu inter茅s en colaborar! Este proyecto busca ser una herramienta abierta y 煤til para evaluaciones educativas desde nivel b谩sico hasta avanzado.

## C贸mo empezar
- Clona el repo y crea un entorno:
  - `make install` (o ver README para pasos manuales con venv)
- Verifica que todo corre localmente:
  - `make validate` y `make test`
  - `python -m src.main` para ejecutar el simulador

## Flujo de trabajo de desarrollo
- Formato y estilo: `make fmt && make lint`
- Pruebas y cobertura: `make test` y `make cov`
- Validaci贸n de datos: `make data-check` (falla si falta cobertura en alg煤n tema)
- Documentaci贸n: consulta `docs/` (quickstart, authoring, taxonomy, blueprint, rubrics, stats)

## Agregar preguntas (banco de datos)
- Opci贸n modular por leaf (recomendada para contribuciones):
  1. Divide (una vez): `python scripts/split_questions.py`
  2. Edita `src/data/questions/<leaf>.json`
  3. Empaqueta: `python scripts/bundle_questions.py` o `make bundle`
  4. Valida: `python scripts/validate_questions.py --strict-coverage`
- Asistente interactivo: `python -m src.main add` (requiere `inquirer`)
- Sigue las pautas de `docs/authoring.md` (esquema, dificultad, explicaci贸n, metadatos)

## Pull Requests
- Crea una rama desde `main`: `feat/...`, `fix/...`, `docs/...`
- Asegura pasar `make fmt lint test data-check`
- Describe claramente el cambio (motivo, alcance, impacto)
- Para cambios en datos, incluye una nota de cobertura (qu茅 leaves tocaste)

## C贸digo de conducta y seguridad
- Cumple el [C贸digo de Conducta](CODE_OF_CONDUCT.md)
- Reporta vulnerabilidades siguiendo la [pol铆tica de seguridad](SECURITY.md)

隆Gracias por contribuir! 
